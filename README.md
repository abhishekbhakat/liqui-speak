# Liqui-Speak ğŸ¤

**One-command setup for real-time audio transcription using LFM2-Audio-1.5B**

Liqui-Speak automates the entire setup process for audio transcription, handling system dependencies, model downloads, and format conversions automatically.

## ğŸš€ Quick Start

```bash
# Install the package
pip install liqui-speak

# Run one-time setup (installs everything)
liqui-speak config

# Transcribe any audio file
liqui-speak audio.m4a
```

## âœ¨ Features

- **ğŸ”„ Auto-setup**: Single command installs all dependencies
- **ğŸ“ Format support**: M4A, AAC, WAV, MP3, FLAC, and more
- **âš¡ Fast conversion**: PyDub-based in-memory processing
- **ğŸ¯ Cross-platform**: macOS, Linux, Windows support
- **ğŸ“¦ Complete automation**: Downloads models, binaries, libraries
- **ğŸ”§ Zero configuration**: Works out of the box

## ğŸ“‹ Installation

### Prerequisites

- Python >= 3.12
- One of: Homebrew (macOS), apt/yum/pacman (Linux), Chocolatey (Windows)

### Install Package

```bash
pip install liqui-speak
```

### First-time Setup

```bash
liqui-speak config
```

This will:

- Install PortAudio and FFmpeg system dependencies
- Download LFM2-Audio-1.5B model files (~1.5GB)
- Download platform-specific llama.cpp binary
- Verify installation

## ğŸ¤ Usage

### Basic Transcription

```bash
# Transcribe any audio file (both formats work)
liqui-speak audio.m4a                    # Simple format
liqui-speak transcribe audio.m4a         # Explicit format

# Or with different file types
liqui-speak recording.wav
liqui-speak podcast.mp3
```

### Advanced Options

```bash
# Play audio during transcription
liqui-speak audio.m4a --play-audio

# Enable text cleaning
liqui-speak audio.wav --clean-text

# Verbose output
liqui-speak audio.mp3 --verbose
```

### Python API

```python
from liqui_speak import transcribe

# Transcribe audio file
text = transcribe("audio.m4a")
print(text)
```

## ğŸ”§ Configuration

### Environment Variables

```bash
export LIQUI_SPEAK_MODEL_DIR="/custom/path"
export LIQUI_SPEAK_SAMPLE_RATE="44100"
```

### Setup Directory

Configuration and models are stored in `~/.liqui_speak/`

## ğŸ“Š Supported Formats

**âœ… Native support**: WAV, FLAC, OGG, AIFF, MP3
**âœ… Auto-converted**: M4A, AAC, ALAC (Apple), WMA
**âŒ Not supported**: DRM-protected files

## ğŸ—ï¸ Development

### Setup Development Environment

```bash
# Clone repository
git clone https://github.com/abhishekbhakat/liqui-speak.git
cd liqui-speak

# Install with dev dependencies
make install-dev

# Run quality checks
make lint
make type-check
make test
```

### Project Structure

```
liqui-speak/
â”œâ”€â”€ src/liqui_speak/
â”‚   â”œâ”€â”€ setup_manager.py    # Automated setup logic
â”‚   â”œâ”€â”€ audio_converter.py  # PyDub-based conversion
â”‚   â”œâ”€â”€ model_downloader.py # Hugging Face downloads
â”‚   â”œâ”€â”€ transcription.py    # Core transcription
â”‚   â””â”€â”€ cli.py             # Command-line interface
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ Makefile               # Development commands
â””â”€â”€ pyproject.toml         # Project configuration
```

## ğŸ” Troubleshooting

### "Format not recognized" error

Your file might be M4A with wrong extension. Use:

```bash
liqui-speak config  # Will detect and convert automatically
```

### Missing system dependencies

Run setup again:

```bash
liqui-speak config --verbose
```

### Model download fails

Check internet connection and available disk space (~2GB needed).

### Permission errors

Make sure you have admin/sudo access for system dependency installation.

## ğŸš€ Performance

- **Setup time**: < 5 minutes (first run)
- **Conversion speed**: < 10% of audio duration
- **Memory usage**: ~2GB during transcription
- **Model size**: ~1.5GB

## ğŸ”— Dependencies

### Python Packages

- `pydub` - Audio conversion
- `soundfile` - Audio I/O
- `huggingface-hub` - Model downloads
- `click` - CLI framework
- `python-magic` - Format detection

### System Dependencies

- `portaudio` - Audio I/O library
- `ffmpeg` - Audio format support

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Make changes and test: `make quality`
4. Commit changes: `git commit -am 'Add feature'`
5. Push to branch: `git push origin feature-name`
6. Submit pull request

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/abhishekbhakat/liqui-speak/issues)
- **Discussions**: [GitHub Discussions](https://github.com/abhishekbhakat/liqui-speak/discussions)
- **Discord**: [Join our server](https://discord.gg/your-invite)

## ğŸ™ Acknowledgments

- **LFM2-Audio-1.5B model**: LiquidAI team
- **llama.cpp**: Georgi Gerganov
- **PyDub**: James Robert
- **Hugging Face**: Model hosting platform
